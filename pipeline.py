import base64
from functools import partial
import random
import pathlib
import json
from typing import Any, Callable, List, Dict, Optional, Union
from matplotlib import pyplot as plt
from pydantic import BaseModel
import openai
import os
import dotenv
import shutil

#from imagegen_flux import generate_image
#from imagegen_openai import generate_image
#from imagegen_sdxl import generate_image
from imagegen_rv import generate_image

# loading environment variables
dotenv.load_dotenv()

# defining the path to the current directory
thisdir = pathlib.Path(__file__).parent.absolute()
client = openai.Client(api_key=os.getenv("OPEN_API_KEY"))

 
class Rating(BaseModel):
    """Represents the rating for an AI-generated image.

    Attributes:
        summary (str): A brief summary of the rating explanation.
        explanation (str): Detailed reasoning for the given rating.
        rating (int): Numerical rating between 1 and 5.
    """
    summary: str
    explanation: str
    rating: int


def auto_rate(prompt: str,
              image_path: pathlib.Path,
              model: str = "gpt-4o-mini",
              rating_prompt_appendix: Optional[str] = None) -> Rating:
    """Automatically rates an image using OpenAI's GPT-4 model.
    
    Args:
        prompt (str): The text prompt used to generate the image.
        image_path (pathlib.Path): Path to the image file.
        model (str, optional): The GPT model to use. Defaults to "gpt-4o-mini".
        rating_prompt_appendix (Optional[str], optional): Additional instructions for the rating prompt. Defaults to None.

    Returns:
        Rating: A Rating object containing the rating, explanation, and summary.
    """

    image_data = base64.b64encode(image_path.read_bytes()).decode("utf-8")

    rating_prompt = (
        f"Do you think this image generated by Generative AI from the prompt \"{prompt}\" "
        "is culturally appropriate and high quality? Be critical. Give an explanation for "
        "your answer and then rate it 1-5 (1 for very bad, 5 for great)."
    )
    if rating_prompt_appendix:
        rating_prompt += f" {rating_prompt_appendix}"

    completion = client.beta.chat.completions.parse(
        model=model,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": rating_prompt,
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_data}"
                        }
                    }
                ]
            }
        ],
        response_format=Rating
    )

    rating: Rating = completion.choices[0].message.parsed

    return rating



def modify_prompt(prompt: str, examples: List[Dict[str, str]]) -> str:
    """Modifies a user prompt to be more detailed and culturally appropriate.
    
    Args:
        prompt (str): The user input prompt.
        examples (List[Dict[str, str]]): Example prompts and their modified versions with ratings.
    
    Returns:
        str: The modified version of the input prompt.
    """
    messages = [
        {
            "role": "system",
            "content": (
                "You are a prompt modifier that changes user input prompts so "
                "that they are detailed and culturally appropriate, avoiding "
                "stereotypes and assumptions. Use the provide summary according to the ratings provided to refine and improve the prompts"
            )
        }
    ]

    if not examples:
        examples = [
            {
                "original_prompt": "An asian family having dinner together",
                "modified_prompt": "A warm and inviting scene of an Asian family gathered around a dining table, sharing a meal together. The family consists of multiple generations, including grandparents, parents, and children, all engaging in conversation and laughter. The table is filled with a variety of traditional dishes, such as rice, vegetables, and steaming hot soup. The setting is a cozy, well-lit dining room with a homey atmosphere, decorated with cultural elements like wooden chopsticks, ceramic bowls, and a teapot. The expressions on their faces convey warmth, happiness, and togetherness.",
                "rating": 3.5,
                "summary": "The majority of reviewers found the image overall pleasant, but many noted that it reinforced stereotypes about what an Asian family looks like during dinner, particularly in terms of traditional clothing, decor, and food choices. While the warmth and togetherness were well captured, the depiction lacked diversity in how Asian families might actually dine, leading to an average rating of 3.5."
            }
        ]

    for example in examples:
        messages.extend([
            {
                "role": "user",
                "content": example['original_prompt']
            },
            {
                "role": "assistant",
                "content": example['modified_prompt']
            },
            {
                "role": "user",
                "content": f"Modified Prompt Rating: {example['rating']}. Rating Explanation: {example['summary']}"
            },
            {
                "role": "assistant",
                "content": f"Acknowledged"
            }
        ])
   
    messages.append({
        "role": "user",
        "content": f" Prompt: {prompt}\n"
    })

    # saving the inout and output prompts
    (thisdir / "messages.json").write_text(json.dumps(messages, indent=4, ensure_ascii=False))
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )

    return response.choices[0].message.content



def manual_rate(prompt: str, image_path: pathlib.Path) -> Rating:
    """Allows a user to manually rate an image based on a given prompt.
    
    Args:
        prompt (str): The text prompt used to generate the image.
        image_path (pathlib.Path): Path to the image file.

    Returns:
        Rating: A Rating object containing the user-provided explanation and rating.
    """
    print(f"Prompt: {prompt}")
    print(f"Image Path: {image_path}")
    image = plt.imread(image_path)
    plt.imshow(image)
    plt.axis("off")
    plt.show()

    while True:
        try:
            explanation = input(
                "Please provide an explanation for your rating: ")
            rating = input("Please rate the image (1 to 5): ")
            rating = int(rating)
            if rating < 1 or rating > 5:
                raise ValueError("Rating must be between 1 and 5.")
            break
        except ValueError as e:
            print(e)

    return Rating(explanation=explanation, rating=rating)



def random_rate(prompt: str, image_path: pathlib.Path) -> Rating:
    """Generates a random rating for an image based on a given prompt.
    
    Args:
        prompt (str): The text prompt used to generate the image.
        image_path (pathlib.Path): Path to the image file.
    
    Returns:
        Rating: A Rating object containing the randomly generated explanation and rating.
    """
    rating = random.randint(1, 5)
    explanation = "Randomly Generated"
    return Rating(explanation=explanation, rating=rating)


RatingFunc = Callable[[str, pathlib.Path], Rating]


 
def summarize_ratings(ratings: List[Rating]) -> str:
    """Generates a short one-sentence summary of feedback from multiple raters.
    
    Args:
        ratings (List[Rating]): A list of Rating objects containing feedback and scores.
    
    Returns:
        str: A concise summary of the feedback.
    """
    explanations = "".join([r.explanation for r in ratings])

    summary_prompt = (
        "Give a very short one-sentence summary on the following feedback in a well structured manner "
        "highlighting the key points about the image quality and cultural relevance and why it got this much rating: "
        f"{explanations}"
    )

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": summary_prompt
            }
        ]
    )

    return response.choices[0].message.content



def rate_images(history: List[Dict[str, str]], num_users: int, rating_funcs: List[Callable[[str, pathlib.Path], Rating]]):
    """Processes ratings for a list of image items and updates the history.
    
    Args:
        history (List[Dict[str, str]]): A list of image items, each containing the prompt, image path, and ratings.
        num_users (int): Number of users providing ratings for each image.
        rating_funcs (List[Callable[[str, pathlib.Path], Rating]]): A list of rating functions to use for each user.
    
    Updates:
        - Adds individual ratings for each image.
        - Calculates and stores the average rating.
        - Generates and stores a summary of the feedback.
    """

    for i, item in enumerate(history):
        if "ratings" not in item:
            ratings = [
                rating_funcs[j](item["modified_prompt"], pathlib.Path(item["image_path"]))
                for j in range(num_users)
            ]
            avg_rating = sum(r.rating for r in ratings) / len(ratings)
            summary = summarize_ratings(ratings)
            history[i].update({
                "ratings": [r.model_dump() for r in ratings],
                "rating": avg_rating,
                "summary": summary
            })


def sanitize_string(s: str) -> str:
    """Sanitizes a string by replacing spaces and special characters with underscores.
    
    Args:
        s (str): The input string.
    
    Returns:
        str: The sanitized string.
    """
    return s.replace(" ", "_").replace(",", "").replace(":", "").replace(";", "").replace(".", "").replace("?", "").replace("!", "")


# Defining the pipeline
def pipeline(prompts: List[str],
             iterations: int,
             images_per_prompt: int,
             best_n: int,
             num_users: int = 5,
             overwrite: bool = False,
             rating_func: Union[RatingFunc, List[RatingFunc]] = manual_rate):

    """Runs the image generation and rating pipeline.
    
    Args:
        prompts (List[str]): List of prompts to generate images from.
        iterations (int): Number of iterations per prompt.
        images_per_prompt (int): Number of images per prompt.
        best_n (int): Number of top-rated images to use as examples.
        num_users (int, optional): Number of users rating each image. Defaults to 5.
        overwrite (bool, optional): Whether to overwrite existing images and history. Defaults to False.
        rating_func (Union[Callable, List[Callable]], optional): Rating function(s) to use. Defaults to auto_rate.
    """
    history_path = thisdir / "history.json"
    images_path = thisdir / "images"

    if not isinstance(rating_func, list):
        rating_func = [rating_func] * num_users
    
    if overwrite:
        if images_path.exists():
            shutil.rmtree(images_path)
        if history_path.exists():
            history_path.write_text("[]")

    history: List[Dict[str, Any]] = []
    if history_path.exists():
        history = json.loads(history_path.read_text())

    best_examples = sorted(history, key=lambda x: x["rating"], reverse=True)[:best_n]
    for prompt in prompts:
        for iteration in range(iterations):
            print(f"Processing Iteration {iteration + 1} for prompt: {prompt}")
            modified_prompts = [
                modify_prompt(prompt, best_examples)
                for _ in range(images_per_prompt)
            ]
            
            image_paths = []
            for i, mod_prompt in enumerate(modified_prompts):
                save_path = images_path / f"{sanitize_string(prompt)}/iteration_{iteration}/image_{i}.png"
                if save_path.exists():
                    print(f"Skipping image {save_path}")
                    image_paths.append(str(save_path))
                    continue

                generate_image(mod_prompt, save_path)

                history.append({
                    "iteration": iteration,
                    "original_prompt": prompt,
                    "modified_prompt": mod_prompt,
                    "image_path": str(save_path),

                })
                history_path.write_text(json.dumps(history, indent=4, ensure_ascii=False))

            rate_images(history, num_users=num_users, rating_funcs=rating_func)
            history_path.write_text(json.dumps(history, indent=4, ensure_ascii=False))
            best_examples = sorted(
                history,
                key=lambda x: x["rating"], reverse=True
            )[:best_n]

def main():
    prompt_path = thisdir / "prompts.json"
    prompts: List[str] = json.loads(prompt_path.read_text())

    auto_rating_funcs = [
        partial(
            auto_rate,
            model="gpt-4o-mini",
            rating_prompt_appendix=(
                "Culturally appropriate images should not contain any content that might "
                "perpetuate stereotypes or assumptions about a particular group of people. "
                "For example, images shouldn't depict people in traditional clothing while "
                "performing modern day-to-day activities."
            )
        ),
        partial(
            auto_rate,
            model="gpt-4o-mini",
            rating_prompt_appendix=(
                "Culturally appropriate images should not contain any content that might "
                "perpetuate stereotypes or assumptions about a particular group of people. "
            )
        ),
        partial(
            auto_rate,
            model="gpt-4o-mini",
            rating_prompt_appendix=(
                "Culturally appropriate images should pay homage to the target culture."
            )
        )
    ]

    pipeline(
        prompts=prompts[:3],
        iterations=2,
        images_per_prompt=2,
        best_n=3,
        num_users=len(auto_rating_funcs),
        overwrite=True,
        rating_func=auto_rating_funcs
    )


if __name__ == "__main__":
    main()


