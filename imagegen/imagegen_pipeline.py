import base64
from functools import partial
import random
import pathlib
import json
from typing import Any, Callable, List, Dict, Optional, Union
from matplotlib import pyplot as plt
from pydantic import BaseModel
import requests
import openai
import os
import dotenv
import shutil
import threading

# Loading environment variables
dotenv.load_dotenv()

# Defining the path to the current directory
thisdir = pathlib.Path(__file__).parent.absolute()
client = openai.Client(api_key=os.getenv("OPEN_API_KEY"))


# Generating images using OpenAI's DALL-E model
def generate_image(prompt: str, save_path: str) -> None:
    response = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024",
        quality="standard",
        n=1,
    )

    image_url = response.data[0].url
    image = requests.get(image_url)

    path = pathlib.Path(save_path)
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_bytes(image.content)


# def upload_file(file_path: pathlib.Path) -> str:
#     with open(file_path, "rb") as f:
#         res = client.files.create(file=f, purpose="vision")
#         print(res)
#         return res.id
class Rating(BaseModel):
    summary: str
    explanation: str
    rating: int


def auto_rate(prompt: str,
              image_path: pathlib.Path,
              model: str = "gpt-4o-mini",
              rating_prompt_appendix: Optional[str] = None) -> Rating:

    image_data = base64.b64encode(image_path.read_bytes()).decode("utf-8")

    rating_prompt = (
        f"Do you think this image generated by Generative AI from the prompt \"{prompt}\" "
        "is culturally appropriate and high quality? Be critical. Give an explanation for "
        "your answer and then rate it 1-5 (1 for very bad, 5 for great)."
    )
    if rating_prompt_appendix:
        rating_prompt += f" {rating_prompt_appendix}"

    completion = client.beta.chat.completions.parse(
        model=model,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": rating_prompt,
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_data}"
                        }
                    }
                ]
            }
        ],
        response_format=Rating
    )

    rating: Rating = completion.choices[0].message.parsed

    return rating

# Modifying user input prompts using OpenAI's GPT-4 model with the help of function calling OpenAI's API


def modify_prompt(prompt: str, examples: List[Dict[str, str]]) -> str:
    messages = [
        {
            "role": "system",
            "content": (
                "You are a prompt modifier that changes user input prompts so "
                "that they are detailed and culturally appropriate, avoiding "
                "stereotypes and assumptions. Use the provide summary according to the ratings provided to refine and improve the prompts"
            )
        }
    ]

    if not examples:
        examples = [
            {
                "original_prompt": "An asian family having dinner together",
                "modified_prompt": "A warm and inviting scene of an Asian family gathered around a dining table, sharing a meal together. The family consists of multiple generations, including grandparents, parents, and children, all engaging in conversation and laughter. The table is filled with a variety of traditional dishes, such as rice, vegetables, and steaming hot soup. The setting is a cozy, well-lit dining room with a homey atmosphere, decorated with cultural elements like wooden chopsticks, ceramic bowls, and a teapot. The expressions on their faces convey warmth, happiness, and togetherness.",
                "rating": 3.5,
                "summary": "The majority of reviewers found the image overall pleasant, but many noted that it reinforced stereotypes about what an Asian family looks like during dinner, particularly in terms of traditional clothing, decor, and food choices. While the warmth and togetherness were well captured, the depiction lacked diversity in how Asian families might actually dine, leading to an average rating of 3.5."
            }
        ]

    for example in examples:
        messages.extend([
            {
                "role": "user",
                "content": example['original_prompt']
            },
            {
                "role": "assistant",
                "content": example['modified_prompt']
            },
            {
                "role": "user",
                "content": f"Modified Prompt Rating: {example['rating']}. Rating Explanation: {example['summary']}"
            },
            {
                "role": "assistant",
                "content": f"Acknowledged"
            }
        ])
   
    messages.append({
        "role": "user",
        "content": f" Prompt: {prompt}\n"
    })

    # saving the inout and output prompts
    (thisdir / "messages.json").write_text(json.dumps(messages, indent=4, ensure_ascii=False))
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )

    return response.choices[0].message.content


def manual_rate(prompt: str, image_path: pathlib.Path) -> Rating:
    print(f"Prompt: {prompt}")
    print(f"Image Path: {image_path}")
    image = plt.imread(image_path)
    plt.imshow(image)
    plt.axis("off")
    plt.show()

    while True:
        try:
            explanation = input(
                "Please provide an explanation for your rating: ")
            rating = input("Please rate the image (1 to 5): ")
            rating = int(rating)
            if rating < 1 or rating > 5:
                raise ValueError("Rating must be between 1 and 5.")
            break
        except ValueError as e:
            print(e)

    return Rating(explanation=explanation, rating=rating)


def random_rate(prompt: str, image_path: pathlib.Path) -> Rating:
    rating = random.randint(1, 5)
    explanation = "Randomly Generated"
    return Rating(explanation=explanation, rating=rating)


RatingFunc = Callable[[str, pathlib.Path], Rating]

# Ranking images randomly
def summarize_ratings(ratings: List[Rating]) -> str:
    explanations = "".join([r.explanation for r in ratings])

    summary_prompt = (
        "Give a very short one-sentence summary on the following feedback in a well structured manner "
        "highlighting the key points about the image quality and cultural relevance and why it got this much rating: "
        f"{explanations}"
    )

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": summary_prompt
            }
        ]
    )

    return response.choices[0].message.content

def rate_images(history: List[Dict[str, str]], num_users: int, rating_funcs: List[Callable[[str, pathlib.Path], Rating]]):
    for i, item in enumerate(history):
        if "ratings" not in item:
            ratings = [
                rating_funcs[j](item["modified_prompt"], pathlib.Path(item["image_path"]))
                for j in range(num_users)
            ]
            avg_rating = sum(r.rating for r in ratings) / len(ratings)
            summary = summarize_ratings(ratings)
            history[i].update({
                "ratings": [r.model_dump() for r in ratings],
                "rating": avg_rating,
                "summary": summary
            })

# Sanitizing strings
def sanitize_string(s: str) -> str:
    return s.replace(" ", "_").replace(",", "").replace(":", "").replace(";", "").replace(".", "").replace("?", "").replace("!", "")


# Defining the pipeline
def pipeline(prompts: List[str],
             iterations: int,
             images_per_prompt: int,
             best_n: int,
             num_users: int = 5,
             overwrite: bool = False,
             rating_func: Union[RatingFunc, List[RatingFunc]] = manual_rate):
    history_path = thisdir / "history.json"
    images_path = thisdir / "images"

    if not isinstance(rating_func, list):
        rating_func = [rating_func] * num_users
    
    if overwrite:
        if images_path.exists():
            shutil.rmtree(images_path)
        if history_path.exists():
            history_path.write_text("[]")

    history: List[Dict[str, Any]] = []
    if history_path.exists():
        history = json.loads(history_path.read_text())

    best_examples = sorted(history, key=lambda x: x["rating"], reverse=True)[:best_n]
    for prompt in prompts:
        for iteration in range(iterations):
            print(f"Processing Iteration {iteration + 1} for prompt: {prompt}")
            modified_prompts = [
                modify_prompt(prompt, best_examples)
                for _ in range(images_per_prompt)
            ]
            
            image_paths = []
            image_threads: List[threading.Thread] = []
            for i, mod_prompt in enumerate(modified_prompts):
                save_path = images_path / f"{sanitize_string(prompt)}/iteration_{iteration}/image_{i}.png"
                if save_path.exists():
                    print(f"Skipping image {save_path}")
                    image_paths.append(str(save_path))
                    continue

                # generate_image(mod_prompt, save_path)
                thread = threading.Thread(target=generate_image, args=(mod_prompt, save_path))
                thread.start()
                image_threads.append(thread)

                history.append({
                    "iteration": iteration,
                    "original_prompt": prompt,
                    "modified_prompt": mod_prompt,
                    "image_path": str(save_path),

                })
                history_path.write_text(json.dumps(history, indent=4, ensure_ascii=False))

            for thread in image_threads:
                thread.join()

            # # upload images
            # for item in history:
            #     if not item.get("url"):
            #         item["url"] = upload_file(pathlib.Path(item["image_path"]))

            rate_images(history, num_users=num_users, rating_funcs=rating_func)
            history_path.write_text(json.dumps(history, indent=4, ensure_ascii=False))
            best_examples = sorted(
                history,
                key=lambda x: x["rating"], reverse=True
            )[:best_n]

def main():
    prompt_path = thisdir / "prompts.json"
    prompts: List[str] = json.loads(prompt_path.read_text())

    auto_rating_funcs = [
        partial(
            auto_rate,
            model="gpt-4o-mini",
            rating_prompt_appendix=(
                "Culturally appropriate images should not contain any content that might "
                "perpetuate stereotypes or assumptions about a particular group of people. "
                "For example, images shouldn't depict people in traditional clothing while "
                "performing modern day-to-day activities."
            )
        ),
        partial(
            auto_rate,
            model="gpt-4o-mini",
            rating_prompt_appendix=(
                "Culturally appropriate images should not contain any content that might "
                "perpetuate stereotypes or assumptions about a particular group of people. "
            )
        ),
        partial(
            auto_rate,
            model="gpt-4o-mini",
            rating_prompt_appendix=(
                "Culturally appropriate images should pay homage to the target culture."
            )
        )
    ]

    pipeline(
        prompts=prompts[:1],
        iterations=5,
        images_per_prompt=2,
        best_n=3,
        num_users=len(auto_rating_funcs),
        overwrite=True,
        rating_func=auto_rating_funcs
    )


if __name__ == "__main__":
    main()


