import base64
from functools import partial
import random
import pathlib
import json
from typing import Callable, List, Dict, Optional, Union
from matplotlib import pyplot as plt
from pydantic import BaseModel
import requests
import openai
import os
import dotenv
import shutil
import threading

# Loading environment variables
dotenv.load_dotenv()

# Defining the path to the current directory
thisdir = pathlib.Path(__file__).parent.absolute()
client = openai.Client(api_key=os.getenv("OPEN_API_KEY"))


# Generating images using OpenAI's DALL-E model
def generate_image(prompt: str, save_path: str) -> None:
    response = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024",
        quality="standard",
        n=1,
    )

    image_url = response.data[0].url
    image = requests.get(image_url)

    path = pathlib.Path(save_path)
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_bytes(image.content)


# def upload_file(file_path: pathlib.Path) -> str:
#     with open(file_path, "rb") as f:
#         res = client.files.create(file=f, purpose="vision")
#         print(res)
#         return res.id
class Rating(BaseModel):
    explanation: str
    rating: int
    
def auto_rate(prompt: str,
              image_path: pathlib.Path,
              model: str = "gpt-4o-mini",
              rating_prompt_appendix: Optional[str] = None) -> Rating:

    image_data = base64.b64encode(image_path.read_bytes()).decode("utf-8")

    rating_prompt = (
        f"Do you think this image generated by Generative AI from the prompt \"{prompt}\" "
        " is culturally appropriate and high quality? Give an explanation for your answer "
        "and then rate it 1-5 (1 for very bad, 5 for great)."
    )
    if rating_prompt_appendix:
        rating_prompt += f" {rating_prompt_appendix}"

    completion = openai.beta.chat.completions.parse(
        model=model,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": rating_prompt,
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                        "url": f"data:image/png;base64,{image_data}"
                        }
                    }
                ]
            }
        ],
        response_format=Rating
    )

    rating: Rating = completion.choices[0].message.parsed

    return rating

# Modifying user input prompts using OpenAI's GPT-4 model with the help of function calling OpenAI's API
def modify_prompt(prompt: str, examples: List[Dict[str, str]]) -> str:
    messages = [
        {
            "role": "system",
            "content": (
                "You are a prompt modifier that changes user input prompts so "
                "that they are detailed and culturally appropriate, avoiding "
                "stereotypes and assumptions."
            )
        }
    ]
    for example in examples:
        messages.append({
            "role": "user",
            "content": example["original_prompt"]
        })
        messages.append({
            "role": "assistant",
            "content": example["modified_prompt"]
        })

    messages.append({
        "role": "user",
        "content": prompt
    })

    # saving the inout and output prompts
    (thisdir / "messages.json").write_text(json.dumps(messages, indent=4))
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )

    return response.choices[0].message.content


def manual_rate(prompt: str, image_path: pathlib.Path) -> Rating:
    print(f"Prompt: {prompt}")
    print(f"Image Path: {image_path}")
    image = plt.imread(image_path)
    plt.imshow(image)
    plt.axis("off")
    plt.show()

    while True:
        try:
            explanation = input("Please provide an explanation for your rating: ")
            rating = input("Please rate the image (1 to 5): ")
            rating = int(rating)
            if rating < 1 or rating > 5:
                raise ValueError("Rating must be between 1 and 5.")
            break
        except ValueError as e:
            print(e)

    return Rating(explanation=explanation, rating=rating)

def random_rate(prompt: str, image_path: pathlib.Path) -> Rating:
    rating = random.randint(1, 5)
    explanation = "Randomly Generated"
    return Rating(explanation=explanation, rating=rating)


RatingFunc = Callable[[str, pathlib.Path], Rating]
# Ranking images randomly
def rate_images(history: List[Dict[str, str]],
                num_users: int = 5,
                rating_func: Union[RatingFunc, List[RatingFunc]] = auto_rate):
    if not isinstance(rating_func, list):
        rating_func = [rating_func] * num_users
    if len(rating_func) < num_users:
        raise ValueError("Number of rate functions must be greater than or equal to the number of users.")
    for i, item in enumerate(history):
        if not item.get("rating"):
            print(f"Image: {item['image_path']}")

            ratings: List[Rating] = []
            for j in range(num_users):
                rating = rating_func[j](item["modified_prompt"], pathlib.Path(item["image_path"]))
                ratings.append(rating)
            average_rating = sum(rating.rating for rating in ratings) / len(ratings)
            history[i]["ratings"] = [json.loads(rating.model_dump_json()) for rating in ratings]
            history[i]["rating"] = average_rating

            print(f"Image: {item['image_path']} | Ratings: {ratings} | Average Rating: {average_rating:.2f}")


# Sanitizing strings
def sanitize_string(s: str) -> str:
    return s.replace(" ", "_").replace(",", "").replace(":", "").replace(";", "").replace(".", "").replace("?", "").replace("!", "")


# Defining the pipeline
def pipeline(prompts: List[str],
             iterations: int,
             images_per_prompt: int,
             best_n: int,
             num_users: int = 5,
             overwrite: bool = False,
             rating_func: RatingFunc = manual_rate):
    history_path = thisdir / "history.json"
    images_path = thisdir / "images"

    if overwrite:
        if images_path.exists():
            shutil.rmtree(images_path)
        if history_path.exists():
            history_path.write_text("[]")

    history = []
    if history_path.exists():
        history = json.loads(history_path.read_text())

    best_examples = sorted(
        history, key=lambda x: x["rating"], reverse=True)[:best_n]
    for prompt in prompts:
        for iteration in range(iterations):
            print(f"Processing Iteration {iteration + 1} for prompt: {prompt}")

            modified_prompts = [modify_prompt(prompt, best_examples) for _ in range(images_per_prompt)]

            image_paths = []
            image_threads: List[threading.Thread] = []
            for i, mod_prompt in enumerate(modified_prompts):
                save_path = images_path / f"{sanitize_string(prompt)}/iteration_{iteration}/image_{i}.png"
                if save_path.exists():
                    print(f"Skipping image {save_path}")
                    image_paths.append(str(save_path))
                    continue

                # generate_image(mod_prompt, save_path)
                thread = threading.Thread(target=generate_image, args=(mod_prompt, save_path))
                thread.start()
                image_threads.append(thread)

                history.append({
                    "iteration": iteration,
                    "original_prompt": prompt,
                    "modified_prompt": mod_prompt,
                    "image_path": str(save_path)
                })
                history_path.write_text(json.dumps(history, indent=4))

            for thread in image_threads:
                thread.join()

            # # upload images
            # for item in history:
            #     if not item.get("url"):
            #         item["url"] = upload_file(pathlib.Path(item["image_path"]))

            rate_images(history, num_users=num_users, rating_func=rating_func)
            history_path.write_text(json.dumps(history, indent=4))
            best_examples = sorted(history, key=lambda x: x["rating"], reverse=True)[:best_n]


def main():
    prompt_path = thisdir / "prompts.json"
    prompts: List[str] = json.loads(prompt_path.read_text())

    auto_rating_funcs = [
        partial(
            auto_rate,
            model="gpt-4o-mini",
            rating_prompt_appendix=(
                "Culturally appropriate images should not contain any content that might "
                "perpetuate stereotypes or assumptions about a particular group of people. "
                "For example, images shouldn't depict people in traditional clothing while "
                "performing modern day-to-day activities."
            )
        ),
        # partial(
        #     auto_rate,
        #     model="gpt-4o-mini",
        #     rating_prompt_appendix=(
        #         "Culturally appropriate images should not contain any content that might "
        #         "perpetuate stereotypes or assumptions about a particular group of people."
        #     )
        # ),
        # partial(
        #     auto_rate,
        #     model="gpt-4o-mini",
        #     rating_prompt_appendix=(
        #         "Culturally appropriate images should pay homage to the target culture."
        #     )
        # )
    ]

    pipeline(
        prompts=prompts[:1],
        iterations=5,
        images_per_prompt=2,
        best_n=3,
        num_users=len(auto_rating_funcs),
        overwrite=True,
        rating_func=auto_rating_funcs
    )


if __name__ == "__main__":
    main()
